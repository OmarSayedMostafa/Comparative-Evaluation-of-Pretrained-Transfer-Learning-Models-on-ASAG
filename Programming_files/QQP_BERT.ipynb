{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"QQP_BERT.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"faOHJpqgmYAp","colab_type":"text"},"source":["# Sources: [Pytorch finetuning](https://github.com/huggingface/transformers#run_gluepy-fine-tuning-on-glue-tasks-for-sequence-classification)"]},{"cell_type":"code","metadata":{"id":"zCNfOwahhJO8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":683},"outputId":"3826ca31-22a0-44fd-9ebc-cd79552ada19","executionInfo":{"status":"ok","timestamp":1569500495538,"user_tz":-120,"elapsed":20273,"user":{"displayName":"sasi kiran","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBjLTu2dzjRCzp118mQDk2S6UyStqeosof2BUg3dQ=s64","userId":"13357761986237341872"}}},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/99/ca0e4c35ccde7d290de3c9c236d5629d1879b04927e5ace9bd6d9183e236/transformers-2.0.0-py3-none-any.whl (290kB)\n","\u001b[K     |████████████████████████████████| 296kB 5.2MB/s \n","\u001b[?25hCollecting sacremoses (from transformers)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/04/b92425ca552116afdb7698fa3f00ca1c975cfd86a847cf132fd813c5d901/sacremoses-0.0.34.tar.gz (859kB)\n","\u001b[K     |████████████████████████████████| 860kB 43.0MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.16.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Collecting regex (from transformers)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\n","\u001b[K     |████████████████████████████████| 655kB 34.4MB/s \n","\u001b[?25hCollecting sentencepiece (from transformers)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 30.6MB/s \n","\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.9.224)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.13.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.6.16)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: botocore<1.13.0,>=1.12.224 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.12.224)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.224->boto3->transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.224->boto3->transformers) (2.5.3)\n","Building wheels for collected packages: sacremoses, regex\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.34-cp36-none-any.whl size=883992 sha256=756db37231fb9d9ef37cf76e6c01343262dff7dddacfa34a5cd8d88f9792439c\n","  Stored in directory: /root/.cache/pip/wheels/07/b9/5b/8bd674c23e962fbff34420a9fa7a2c374d591ecadd5bc37684\n","  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for regex: filename=regex-2019.8.19-cp36-cp36m-linux_x86_64.whl size=609236 sha256=fdde5f1d73d662122cf27e899e85a9c3c6222e8b24a1ace9b1042ae7472537d3\n","  Stored in directory: /root/.cache/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\n","Successfully built sacremoses regex\n","Installing collected packages: sacremoses, regex, sentencepiece, transformers\n","Successfully installed regex-2019.8.19 sacremoses-0.0.34 sentencepiece-0.1.83 transformers-2.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AxdzMwSxg2ei","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"outputId":"8dd4f40b-96d9-4c87-fc75-d15f597d3366","executionInfo":{"status":"ok","timestamp":1569500505459,"user_tz":-120,"elapsed":3874,"user":{"displayName":"sasi kiran","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBjLTu2dzjRCzp118mQDk2S6UyStqeosof2BUg3dQ=s64","userId":"13357761986237341872"}}},"source":["!python -m pytest -sv ./transformers/tests/\n","!python -m pytest -sv ./examples/"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[1m============================= test session starts ==============================\u001b[0m\n","platform linux -- Python 3.6.8, pytest-3.6.4, py-1.8.0, pluggy-0.7.1 -- /usr/bin/python3\n","cachedir: .pytest_cache\n","rootdir: /content, inifile:\n","\n","\u001b[33m\u001b[1m========================= no tests ran in 0.00 seconds =========================\u001b[0m\n","\u001b[31mERROR: file not found: ./transformers/tests/\n","\u001b[0m\n","\u001b[1m============================= test session starts ==============================\u001b[0m\n","platform linux -- Python 3.6.8, pytest-3.6.4, py-1.8.0, pluggy-0.7.1 -- /usr/bin/python3\n","cachedir: .pytest_cache\n","rootdir: /content, inifile:\n","\n","\u001b[33m\u001b[1m========================= no tests ran in 0.00 seconds =========================\u001b[0m\n","\u001b[31mERROR: file not found: ./examples/\n","\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1o-qKZ__hikd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":557},"outputId":"df7afd0f-7c0a-450c-9de2-879c791fceb1","executionInfo":{"status":"error","timestamp":1569500752817,"user_tz":-120,"elapsed":79659,"user":{"displayName":"sasi kiran","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBjLTu2dzjRCzp118mQDk2S6UyStqeosof2BUg3dQ=s64","userId":"13357761986237341872"}}},"source":["\"\"\" Script for downloading all GLUE data.\n","Example usage:\n","    python download_glue_data.py --data_dir data --tasks all\n","Note: for legal reasons, we are unable to host MRPC.\n","You can either use the version hosted by the SentEval team, which is already tokenized,\n","or you can download the original data from:\n","https://download.microsoft.com/download/D/4/6/D46FF87A-F6B9-4252-AA8B-3604ED519838/MSRParaphraseCorpus.msi  # noqa\n","and extract the data from it manually.\n","For Windows users, you can run the .msi file. For Mac and Linux users, consider an external library\n","such as 'cabextract' (see below for an example). You should then rename and place specific files in\n","a folder (see below for an example).\n","mkdir MRPCA\n","cabextract MSRParaphraseCorpus.msi -d MRPC\n","cat MRPC/_2DEC3DBE877E4DB192D17C0256E90F1D | tr -d $'\\r' > MRPC/msr_paraphrase_train.txt\n","cat MRPC/_D7B391F9EAFF4B1B8BCE8F21B20B1B61 | tr -d $'\\r' > MRPC/msr_paraphrase_test.txt\n","rm MRPC/_*\n","rm MSRParaphraseCorpus.msi\n","\"\"\"\n","\n","\n","\n","TASKS = [\"CoLA\", \"SST\", \"MRPC\", \"QQP\", \"STS\", \"MNLI\", \"SNLI\", \"QNLI\", \"RTE\", \"WNLI\", \"diagnostic\"]\n","TASK2PATH = {\n","    \"CoLA\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FCoLA.zip?alt=media&token=46d5e637-3411-4188-bc44-5809b5bfb5f4\",  # noqa\n","    \"SST\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSST-2.zip?alt=media&token=aabc5f6b-e466-44a2-b9b4-cf6337f84ac8\",  # noqa\n","    \"MRPC\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2Fmrpc_dev_ids.tsv?alt=media&token=ec5c0836-31d5-48f4-b431-7480817f1adc\",  # noqa\n","    \"QQP\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FQQP-clean.zip?alt=media&token=11a647cb-ecd3-49c9-9d31-79f8ca8fe277\",  # noqa\n","    \"STS\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSTS-B.zip?alt=media&token=bddb94a7-8706-4e0d-a694-1109e12273b5\",  # noqa\n","    \"MNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FMNLI.zip?alt=media&token=50329ea1-e339-40e2-809c-10c40afff3ce\",  # noqa\n","    \"SNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSNLI.zip?alt=media&token=4afcfbb2-ff0c-4b2d-a09a-dbf07926f4df\",  # noqa\n","    \"QNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FQNLIv2.zip?alt=media&token=6fdcf570-0fc5-4631-8456-9505272d1601\",  # noqa\n","    \"RTE\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FRTE.zip?alt=media&token=5efa7e85-a0bb-4f19-8ea2-9e1840f077fb\",  # noqa\n","    \"WNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FWNLI.zip?alt=media&token=068ad0a0-ded7-4bd7-99a5-5e00222e0faf\",  # noqa\n","    \"diagnostic\": [\"https://storage.googleapis.com/mtl-sentence-representations.appspot.com/tsvsWithoutLabels%2FAX.tsv?GoogleAccessId=firebase-adminsdk-0khhl@mtl-sentence-representations.iam.gserviceaccount.com&Expires=2498860800&Signature=DuQ2CSPt2Yfre0C%2BiISrVYrIFaZH1Lc7hBVZDD4ZyR7fZYOMNOUGpi8QxBmTNOrNPjR3z1cggo7WXFfrgECP6FBJSsURv8Ybrue8Ypt%2FTPxbuJ0Xc2FhDi%2BarnecCBFO77RSbfuz%2Bs95hRrYhTnByqu3U%2FYZPaj3tZt5QdfpH2IUROY8LiBXoXS46LE%2FgOQc%2FKN%2BA9SoscRDYsnxHfG0IjXGwHN%2Bf88q6hOmAxeNPx6moDulUF6XMUAaXCSFU%2BnRO2RDL9CapWxj%2BDl7syNyHhB7987hZ80B%2FwFkQ3MEs8auvt5XW1%2Bd4aCU7ytgM69r8JDCwibfhZxpaa4gd50QXQ%3D%3D\",  # noqa\n","        \"https://www.dropbox.com/s/ju7d95ifb072q9f/diagnostic-full.tsv?dl=1\",],}\n","\n","MRPC_TRAIN = \"https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt\"\n","MRPC_TEST = \"https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_test.txt\"\n","\n","\n","def download_and_extract(task, data_dir):\n","    print(\"Downloading and extracting %s...\" % task)\n","    data_file = \"%s.zip\" % task\n","    urllib.request.urlretrieve(TASK2PATH[task], data_file)\n","    with zipfile.ZipFile(data_file) as zip_ref:\n","        zip_ref.extractall(data_dir)\n","    os.remove(data_file)\n","    print(\"\\tCompleted!\")\n","\n","\n","def format_mrpc(data_dir, path_to_data):\n","    print(\"Processing MRPC...\")\n","    mrpc_dir = os.path.join(data_dir, \"MRPC\")\n","    if not os.path.isdir(mrpc_dir):\n","        os.mkdir(mrpc_dir)\n","    if path_to_data:\n","        mrpc_train_file = os.path.join(path_to_data, \"msr_paraphrase_train.txt\")\n","        mrpc_test_file = os.path.join(path_to_data, \"msr_paraphrase_test.txt\")\n","    else:\n","        print(\"Local MRPC data not specified, downloading data from %s\" % MRPC_TRAIN)\n","        mrpc_train_file = os.path.join(mrpc_dir, \"msr_paraphrase_train.txt\")\n","        mrpc_test_file = os.path.join(mrpc_dir, \"msr_paraphrase_test.txt\")\n","        urllib.request.urlretrieve(MRPC_TRAIN, mrpc_train_file)\n","        urllib.request.urlretrieve(MRPC_TEST, mrpc_test_file)\n","    assert os.path.isfile(mrpc_train_file), \"Train data not found at %s\" % mrpc_train_file\n","    assert os.path.isfile(mrpc_test_file), \"Test data not found at %s\" % mrpc_test_file\n","    urllib.request.urlretrieve(TASK2PATH[\"MRPC\"], os.path.join(mrpc_dir, \"dev_ids.tsv\"))\n","\n","    dev_ids = []\n","    with open(os.path.join(mrpc_dir, \"dev_ids.tsv\"), encoding=\"utf8\") as ids_fh:\n","        for row in ids_fh:\n","            dev_ids.append(row.strip().split(\"\\t\"))\n","\n","    with open(mrpc_train_file, encoding=\"utf8\") as data_fh, open(\n","        os.path.join(mrpc_dir, \"train.tsv\"), \"w\", encoding=\"utf8\"\n","    ) as train_fh, open(os.path.join(mrpc_dir, \"dev.tsv\"), \"w\", encoding=\"utf8\") as dev_fh:\n","        header = data_fh.readline()\n","        train_fh.write(header)\n","        dev_fh.write(header)\n","        for row in data_fh:\n","            label, id1, id2, s1, s2 = row.strip().split(\"\\t\")\n","            if [id1, id2] in dev_ids:\n","                dev_fh.write(\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (label, id1, id2, s1, s2))\n","            else:\n","                train_fh.write(\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (label, id1, id2, s1, s2))\n","\n","    with open(mrpc_test_file, encoding=\"utf8\") as data_fh, open(\n","        os.path.join(mrpc_dir, \"test.tsv\"), \"w\", encoding=\"utf8\"\n","    ) as test_fh:\n","        header = data_fh.readline()\n","        test_fh.write(\"index\\t#1 ID\\t#2 ID\\t#1 String\\t#2 String\\n\")\n","        for idx, row in enumerate(data_fh):\n","            label, id1, id2, s1, s2 = row.strip().split(\"\\t\")\n","            test_fh.write(\"%d\\t%s\\t%s\\t%s\\t%s\\n\" % (idx, id1, id2, s1, s2))\n","    print(\"\\tCompleted!\")\n","\n","\n","def download_diagnostic(data_dir):\n","    print(\"Downloading and extracting diagnostic data...\")\n","    if not os.path.isdir(os.path.join(data_dir, \"MNLI\")):\n","        os.mkdir(os.path.join(data_dir, \"MNLI\"))\n","    data_file = os.path.join(data_dir, \"MNLI\", \"diagnostic.tsv\")\n","    urllib.request.urlretrieve(TASK2PATH[\"diagnostic\"][0], data_file)\n","    data_file = os.path.join(data_dir, \"MNLI\", \"diagnostic-full.tsv\")\n","    urllib.request.urlretrieve(TASK2PATH[\"diagnostic\"][1], data_file)\n","    print(\"\\tCompleted!\")\n","    return\n","\n","\n","def get_tasks(task_names):\n","    task_names = task_names.split(\",\")\n","    if \"all\" in task_names:\n","        tasks = TASKS\n","    else:\n","        tasks = []\n","        for task_name in task_names:\n","            assert task_name in TASKS, \"Task %s not found!\" % task_name\n","            tasks.append(task_name)\n","        if \"MNLI\" in tasks and \"diagnostic\" not in tasks:\n","            tasks.append(\"diagnostic\")\n","\n","    return tasks\n","\n","\n","def main(arguments):\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\n","        \"--data_dir\", help=\"directory to save data to\", type=str, default=\"glue_data\"\n","    )\n","    parser.add_argument(\n","        \"--tasks\",\n","        help=\"tasks to download data for as a comma separated string\",\n","        type=str,\n","        default=\"all\",\n","    )\n","    parser.add_argument(\n","        \"--path_to_mrpc\",\n","        help=\"path to directory containing extracted MRPC data, msr_paraphrase_train.txt and \"\n","        \"msr_paraphrase_text.txt\",\n","        type=str,\n","        default=\"\",\n","    )\n","    args = parser.parse_known_args(arguments)[0]\n","\n","    if not os.path.isdir(args.data_dir):\n","        os.mkdir(args.data_dir)\n","    tasks = get_tasks(args.tasks)\n","\n","    for task in tasks:\n","        if task == \"MRPC\":\n","            format_mrpc(args.data_dir, args.path_to_mrpc)\n","        elif task == \"diagnostic\":\n","            download_diagnostic(args.data_dir)\n","        else:\n","            download_and_extract(task, args.data_dir)\n","\n","\n","if __name__ == \"__main__\":\n","    sys.exit(main(sys.argv[1:]))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Downloading and extracting CoLA...\n","\tCompleted!\n","Downloading and extracting SST...\n","\tCompleted!\n","Processing MRPC...\n","Local MRPC data not specified, downloading data from https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt\n","\tCompleted!\n","Downloading and extracting QQP...\n","\tCompleted!\n","Downloading and extracting STS...\n","\tCompleted!\n","Downloading and extracting MNLI...\n","\tCompleted!\n","Downloading and extracting SNLI...\n","\tCompleted!\n","Downloading and extracting QNLI...\n","\tCompleted!\n","Downloading and extracting RTE...\n","\tCompleted!\n","Downloading and extracting WNLI...\n","\tCompleted!\n","Downloading and extracting diagnostic data...\n","\tCompleted!\n"],"name":"stdout"},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\n"]},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Vw__0OOKhrT_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"24194358-ae82-4b6b-a40a-344c8fb7808f","executionInfo":{"status":"ok","timestamp":1569500801366,"user_tz":-120,"elapsed":4241,"user":{"displayName":"sasi kiran","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBjLTu2dzjRCzp118mQDk2S6UyStqeosof2BUg3dQ=s64","userId":"13357761986237341872"}}},"source":["! git clone https://github.com/huggingface/transformers transformers"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Cloning into 'transformers'...\n","remote: Enumerating objects: 106, done.\u001b[K\n","remote: Counting objects: 100% (106/106), done.\u001b[K\n","remote: Compressing objects: 100% (61/61), done.\u001b[K\n","remote: Total 9043 (delta 62), reused 72 (delta 45), pack-reused 8937\u001b[K\n","Receiving objects: 100% (9043/9043), 4.86 MiB | 11.65 MiB/s, done.\n","Resolving deltas: 100% (6535/6535), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tx2-krhziZgX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":241},"outputId":"17487069-207d-4634-bb9c-c707c82c1803","executionInfo":{"status":"ok","timestamp":1569500850079,"user_tz":-120,"elapsed":4393,"user":{"displayName":"sasi kiran","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBjLTu2dzjRCzp118mQDk2S6UyStqeosof2BUg3dQ=s64","userId":"13357761986237341872"}}},"source":["!pip install -r /content/transformers/examples/requirements.txt"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Collecting tensorboardX (from -r /content/transformers/examples/requirements.txt (line 1))\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/12/dcaf67e1312475b26db9e45e7bb6f32b540671a9ee120b3a72d9e09bc517/tensorboardX-1.8-py2.py3-none-any.whl (216kB)\n","\u001b[K     |████████████████████████████████| 225kB 4.9MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r /content/transformers/examples/requirements.txt (line 2)) (0.21.3)\n","Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r /content/transformers/examples/requirements.txt (line 1)) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r /content/transformers/examples/requirements.txt (line 1)) (1.16.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r /content/transformers/examples/requirements.txt (line 1)) (1.12.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r /content/transformers/examples/requirements.txt (line 2)) (0.13.2)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r /content/transformers/examples/requirements.txt (line 2)) (1.3.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX->-r /content/transformers/examples/requirements.txt (line 1)) (41.2.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-1.8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z717opIFilW_","colab_type":"code","colab":{}},"source":["!export GLUE_DIR=/content/glue_data\n","!export TASK_NAME=STS\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"paXQ2cOsixb7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"531df7b5-d387-402f-825c-ecf986b867f2"},"source":["!python /content/transformers/examples/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name sts-b \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_lower_case \\\n","    --data_dir /content/glue_data/STS-B \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=8   \\\n","    --per_gpu_train_batch_size=8   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 3.0 \\\n","    --output_dir /tmp/STS"],"execution_count":0,"outputs":[{"output_type":"stream","text":["09/26/2019 12:45:51 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n","09/26/2019 12:45:51 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n","09/26/2019 12:45:51 - INFO - transformers.configuration_utils -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"sts-b\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","09/26/2019 12:45:51 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","09/26/2019 12:45:51 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","09/26/2019 12:45:56 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","09/26/2019 12:45:56 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","09/26/2019 12:45:56 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='/content/glue_data/STS-B', device=device(type='cpu'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=0, no_cuda=False, num_train_epochs=3.0, output_dir='/tmp/STS', output_mode='regression', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, save_steps=50, seed=42, server_ip='', server_port='', task_name='sts-b', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n","09/26/2019 12:45:56 - INFO - __main__ -   Creating features from dataset file at /content/glue_data/STS-B\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   Writing example 0\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   *** Example ***\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   guid: train-0\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   input_ids: 101 1037 4946 2003 2635 2125 1012 102 2019 2250 4946 2003 2635 2125 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   label: 5.000 (id = 5)\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   *** Example ***\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   guid: train-1\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   input_ids: 101 1037 2158 2003 2652 1037 2312 8928 1012 102 1037 2158 2003 2652 1037 8928 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   label: 3.800 (id = 3)\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   *** Example ***\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   guid: train-2\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   input_ids: 101 1037 2158 2003 9359 14021 5596 2098 8808 2006 1037 10733 1012 102 1037 2158 2003 9359 29022 8808 2006 2019 4895 3597 23461 10733 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   label: 3.800 (id = 3)\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   *** Example ***\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   guid: train-3\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   input_ids: 101 2093 2273 2024 2652 7433 1012 102 2048 2273 2024 2652 7433 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   label: 2.600 (id = 2)\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   *** Example ***\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   guid: train-4\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   input_ids: 101 1037 2158 2003 2652 1996 10145 1012 102 1037 2158 8901 2003 2652 1996 10145 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","09/26/2019 12:45:56 - INFO - transformers.data.processors.glue -   label: 4.250 (id = 4)\n","09/26/2019 12:46:02 - INFO - __main__ -   Saving features into cached file /content/glue_data/STS-B/cached_train_bert-base-uncased_128_sts-b\n","09/26/2019 12:46:03 - INFO - __main__ -   ***** Running training *****\n","09/26/2019 12:46:03 - INFO - __main__ -     Num examples = 5749\n","09/26/2019 12:46:03 - INFO - __main__ -     Num Epochs = 3\n","09/26/2019 12:46:03 - INFO - __main__ -     Instantaneous batch size per GPU = 8\n","09/26/2019 12:46:03 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 8\n","09/26/2019 12:46:03 - INFO - __main__ -     Gradient Accumulation steps = 1\n","09/26/2019 12:46:03 - INFO - __main__ -     Total optimization steps = 2157\n","Epoch:   0% 0/3 [00:00<?, ?it/s]\n","Iteration:   0% 0/719 [00:00<?, ?it/s]\u001b[A\n","Iteration:   0% 1/719 [00:13<2:36:04, 13.04s/it]\u001b[A\n","Iteration:   0% 2/719 [00:26<2:37:08, 13.15s/it]\u001b[A\n","Iteration:   0% 3/719 [00:39<2:37:10, 13.17s/it]\u001b[A\n","Iteration:   1% 4/719 [00:52<2:36:42, 13.15s/it]\u001b[A\n","Iteration:   1% 5/719 [01:05<2:36:01, 13.11s/it]\u001b[A\n","Iteration:   1% 6/719 [01:18<2:35:53, 13.12s/it]\u001b[A\n","Iteration:   1% 7/719 [01:32<2:35:32, 13.11s/it]\u001b[A\n","Iteration:   1% 8/719 [01:45<2:35:22, 13.11s/it]\u001b[A\n","Iteration:   1% 9/719 [01:58<2:34:53, 13.09s/it]\u001b[A\n","Iteration:   1% 10/719 [02:11<2:34:28, 13.07s/it]\u001b[A\n","Iteration:   2% 11/719 [02:24<2:34:00, 13.05s/it]\u001b[A\n","Iteration:   2% 12/719 [02:37<2:33:43, 13.05s/it]\u001b[A\n","Iteration:   2% 13/719 [02:50<2:33:29, 13.04s/it]\u001b[A\n","Iteration:   2% 14/719 [03:03<2:33:06, 13.03s/it]\u001b[A\n","Iteration:   2% 15/719 [03:16<2:32:54, 13.03s/it]\u001b[A\n","Iteration:   2% 16/719 [03:29<2:32:40, 13.03s/it]\u001b[A\n","Iteration:   2% 17/719 [03:42<2:32:12, 13.01s/it]\u001b[A\n","Iteration:   3% 18/719 [03:55<2:32:08, 13.02s/it]\u001b[A\n","Iteration:   3% 19/719 [04:08<2:32:00, 13.03s/it]\u001b[A\n","Iteration:   3% 20/719 [04:21<2:32:02, 13.05s/it]\u001b[A\n","Iteration:   3% 21/719 [04:34<2:31:55, 13.06s/it]\u001b[A\n","Iteration:   3% 22/719 [04:47<2:31:49, 13.07s/it]\u001b[A\n","Iteration:   3% 23/719 [05:00<2:31:44, 13.08s/it]\u001b[A\n","Iteration:   3% 24/719 [05:13<2:31:20, 13.07s/it]\u001b[A\n","Iteration:   3% 25/719 [05:26<2:31:03, 13.06s/it]\u001b[A\n","Iteration:   4% 26/719 [05:39<2:30:56, 13.07s/it]\u001b[A\n","Iteration:   4% 27/719 [05:52<2:30:41, 13.07s/it]\u001b[A\n","Iteration:   4% 28/719 [06:06<2:30:33, 13.07s/it]\u001b[A\n","Iteration:   4% 29/719 [06:19<2:30:23, 13.08s/it]\u001b[A\n","Iteration:   4% 30/719 [06:32<2:29:52, 13.05s/it]\u001b[A\n","Iteration:   4% 31/719 [06:45<2:29:23, 13.03s/it]\u001b[A\n","Iteration:   4% 32/719 [06:58<2:29:19, 13.04s/it]\u001b[A\n","Iteration:   5% 33/719 [07:11<2:29:04, 13.04s/it]\u001b[A\n","Iteration:   5% 34/719 [07:24<2:28:48, 13.03s/it]\u001b[A\n","Iteration:   5% 35/719 [07:37<2:28:43, 13.05s/it]\u001b[A\n","Iteration:   5% 36/719 [07:50<2:28:40, 13.06s/it]\u001b[A\n","Iteration:   5% 37/719 [08:03<2:28:35, 13.07s/it]\u001b[A\n","Iteration:   5% 38/719 [08:16<2:28:26, 13.08s/it]\u001b[A\n","Iteration:   5% 39/719 [08:29<2:28:10, 13.07s/it]\u001b[A\n","Iteration:   6% 40/719 [08:42<2:27:56, 13.07s/it]\u001b[A\n","Iteration:   6% 41/719 [08:55<2:27:36, 13.06s/it]\u001b[A\n","Iteration:   6% 42/719 [09:08<2:26:30, 12.98s/it]\u001b[A\n","Iteration:   6% 43/719 [09:21<2:25:51, 12.95s/it]\u001b[A\n","Iteration:   6% 44/719 [09:34<2:25:44, 12.95s/it]\u001b[A\n","Iteration:   6% 45/719 [09:47<2:24:58, 12.91s/it]\u001b[A\n","Iteration:   6% 46/719 [09:59<2:24:12, 12.86s/it]\u001b[A\n","Iteration:   7% 47/719 [10:12<2:23:25, 12.81s/it]\u001b[A\n","Iteration:   7% 48/719 [10:25<2:23:07, 12.80s/it]\u001b[A\n","Iteration:   7% 49/719 [10:38<2:22:46, 12.79s/it]\u001b[A09/26/2019 12:56:54 - INFO - transformers.configuration_utils -   Configuration saved in /tmp/STS/checkpoint-50/config.json\n","09/26/2019 12:56:56 - INFO - transformers.modeling_utils -   Model weights saved in /tmp/STS/checkpoint-50/pytorch_model.bin\n","09/26/2019 12:56:56 - INFO - __main__ -   Saving model checkpoint to /tmp/STS/checkpoint-50\n","\n","Iteration:   7% 50/719 [10:52<2:28:20, 13.30s/it]\u001b[A\n","Iteration:   7% 51/719 [11:05<2:26:56, 13.20s/it]\u001b[A\n","Iteration:   7% 52/719 [11:18<2:25:38, 13.10s/it]\u001b[A\n","Iteration:   7% 53/719 [11:31<2:24:23, 13.01s/it]\u001b[A\n","Iteration:   8% 54/719 [11:44<2:23:55, 12.99s/it]\u001b[A\n","Iteration:   8% 55/719 [11:57<2:23:34, 12.97s/it]\u001b[A\n","Iteration:   8% 56/719 [12:10<2:22:53, 12.93s/it]\u001b[A\n","Iteration:   8% 57/719 [12:22<2:22:35, 12.92s/it]\u001b[A\n","Iteration:   8% 58/719 [12:35<2:22:23, 12.93s/it]\u001b[A\n","Iteration:   8% 59/719 [12:48<2:22:09, 12.92s/it]\u001b[A\n","Iteration:   8% 60/719 [13:01<2:21:37, 12.89s/it]\u001b[A\n","Iteration:   8% 61/719 [13:14<2:20:50, 12.84s/it]\u001b[A\n","Iteration:   9% 62/719 [13:27<2:20:16, 12.81s/it]\u001b[A\n","Iteration:   9% 63/719 [13:39<2:20:01, 12.81s/it]\u001b[A\n","Iteration:   9% 64/719 [13:52<2:20:04, 12.83s/it]\u001b[A\n","Iteration:   9% 65/719 [14:05<2:20:27, 12.89s/it]\u001b[A\n","Iteration:   9% 66/719 [14:18<2:20:22, 12.90s/it]\u001b[A\n","Iteration:   9% 67/719 [14:31<2:20:12, 12.90s/it]\u001b[A\n","Iteration:   9% 68/719 [14:44<2:19:48, 12.89s/it]\u001b[A\n","Iteration:  10% 69/719 [14:57<2:19:24, 12.87s/it]\u001b[A\n","Iteration:  10% 70/719 [15:10<2:18:58, 12.85s/it]\u001b[A\n","Iteration:  10% 71/719 [15:22<2:18:39, 12.84s/it]\u001b[A\n","Iteration:  10% 72/719 [15:35<2:18:40, 12.86s/it]\u001b[A\n","Iteration:  10% 73/719 [15:48<2:18:52, 12.90s/it]\u001b[A\n","Iteration:  10% 74/719 [16:01<2:18:42, 12.90s/it]\u001b[A\n","Iteration:  10% 75/719 [16:14<2:18:19, 12.89s/it]\u001b[A\n","Iteration:  11% 76/719 [16:27<2:18:18, 12.91s/it]\u001b[A\n","Iteration:  11% 77/719 [16:40<2:17:45, 12.87s/it]\u001b[A\n","Iteration:  11% 78/719 [16:53<2:17:09, 12.84s/it]\u001b[A\n","Iteration:  11% 79/719 [17:05<2:16:48, 12.83s/it]\u001b[A\n","Iteration:  11% 80/719 [17:18<2:16:21, 12.80s/it]\u001b[A\n","Iteration:  11% 81/719 [17:31<2:16:10, 12.81s/it]\u001b[A\n","Iteration:  11% 82/719 [17:44<2:16:14, 12.83s/it]\u001b[A\n","Iteration:  12% 83/719 [17:57<2:16:30, 12.88s/it]\u001b[A\n","Iteration:  12% 84/719 [18:10<2:16:29, 12.90s/it]\u001b[A\n","Iteration:  12% 85/719 [18:23<2:16:03, 12.88s/it]\u001b[A\n","Iteration:  12% 86/719 [18:35<2:15:34, 12.85s/it]\u001b[A\n","Iteration:  12% 87/719 [18:48<2:15:05, 12.83s/it]\u001b[A\n","Iteration:  12% 88/719 [19:01<2:14:22, 12.78s/it]\u001b[A\n","Iteration:  12% 89/719 [19:13<2:13:52, 12.75s/it]\u001b[A\n","Iteration:  13% 90/719 [19:26<2:13:26, 12.73s/it]\u001b[A\n","Iteration:  13% 91/719 [19:39<2:13:21, 12.74s/it]\u001b[A\n","Iteration:  13% 92/719 [19:52<2:13:26, 12.77s/it]\u001b[A\n","Iteration:  13% 93/719 [20:05<2:13:06, 12.76s/it]\u001b[A\n","Iteration:  13% 94/719 [20:17<2:12:34, 12.73s/it]\u001b[A\n","Iteration:  13% 95/719 [20:30<2:12:17, 12.72s/it]\u001b[A\n","Iteration:  13% 96/719 [20:43<2:12:02, 12.72s/it]\u001b[A\n","Iteration:  13% 97/719 [20:55<2:11:51, 12.72s/it]\u001b[A\n","Iteration:  14% 98/719 [21:08<2:11:41, 12.72s/it]\u001b[A\n","Iteration:  14% 99/719 [21:21<2:11:32, 12.73s/it]\u001b[A09/26/2019 13:07:37 - INFO - transformers.configuration_utils -   Configuration saved in /tmp/STS/checkpoint-100/config.json\n","09/26/2019 13:07:39 - INFO - transformers.modeling_utils -   Model weights saved in /tmp/STS/checkpoint-100/pytorch_model.bin\n","09/26/2019 13:07:39 - INFO - __main__ -   Saving model checkpoint to /tmp/STS/checkpoint-100\n","\n","Iteration:  14% 100/719 [21:35<2:16:56, 13.27s/it]\u001b[A\n","Iteration:  14% 101/719 [21:48<2:15:37, 13.17s/it]\u001b[A\n","Iteration:  14% 102/719 [22:01<2:14:00, 13.03s/it]\u001b[A\n","Iteration:  14% 103/719 [22:14<2:12:59, 12.95s/it]\u001b[A\n","Iteration:  14% 104/719 [22:26<2:12:02, 12.88s/it]\u001b[A\n","Iteration:  15% 105/719 [22:39<2:11:13, 12.82s/it]\u001b[A\n","Iteration:  15% 106/719 [22:52<2:10:36, 12.78s/it]\u001b[A\n","Iteration:  15% 107/719 [23:05<2:10:12, 12.77s/it]\u001b[A\n","Iteration:  15% 108/719 [23:17<2:09:42, 12.74s/it]\u001b[A\n","Iteration:  15% 109/719 [23:30<2:09:32, 12.74s/it]\u001b[A\n","Iteration:  15% 110/719 [23:43<2:09:14, 12.73s/it]\u001b[A\n","Iteration:  15% 111/719 [23:55<2:09:01, 12.73s/it]\u001b[A\n","Iteration:  16% 112/719 [24:08<2:08:43, 12.72s/it]\u001b[A\n","Iteration:  16% 113/719 [24:21<2:08:33, 12.73s/it]\u001b[A\n","Iteration:  16% 114/719 [24:34<2:08:26, 12.74s/it]\u001b[A\n","Iteration:  16% 115/719 [24:46<2:08:19, 12.75s/it]\u001b[A\n","Iteration:  16% 116/719 [24:59<2:08:31, 12.79s/it]\u001b[A\n","Iteration:  16% 117/719 [25:12<2:08:42, 12.83s/it]\u001b[A\n","Iteration:  16% 118/719 [25:25<2:08:49, 12.86s/it]\u001b[A\n","Iteration:  17% 119/719 [25:38<2:09:00, 12.90s/it]\u001b[A\n","Iteration:  17% 120/719 [25:51<2:08:55, 12.91s/it]\u001b[A\n","Iteration:  17% 121/719 [26:04<2:08:49, 12.93s/it]\u001b[A\n","Iteration:  17% 122/719 [26:17<2:08:12, 12.88s/it]\u001b[A\n","Iteration:  17% 123/719 [26:30<2:07:42, 12.86s/it]\u001b[A\n","Iteration:  17% 124/719 [26:42<2:07:19, 12.84s/it]\u001b[A\n","Iteration:  17% 125/719 [26:55<2:07:12, 12.85s/it]\u001b[A\n","Iteration:  18% 126/719 [27:08<2:06:55, 12.84s/it]\u001b[A\n","Iteration:  18% 127/719 [27:21<2:06:48, 12.85s/it]\u001b[A\n","Iteration:  18% 128/719 [27:34<2:06:33, 12.85s/it]\u001b[A\n","Iteration:  18% 129/719 [27:47<2:06:39, 12.88s/it]\u001b[A\n","Iteration:  18% 130/719 [28:00<2:06:38, 12.90s/it]\u001b[A\n","Iteration:  18% 131/719 [28:13<2:06:45, 12.93s/it]\u001b[A\n","Iteration:  18% 132/719 [28:26<2:06:52, 12.97s/it]\u001b[A\n","Iteration:  18% 133/719 [28:39<2:06:42, 12.97s/it]\u001b[A\n","Iteration:  19% 134/719 [28:52<2:06:39, 12.99s/it]\u001b[A\n","Iteration:  19% 135/719 [29:05<2:06:26, 12.99s/it]\u001b[A\n","Iteration:  19% 136/719 [29:18<2:06:06, 12.98s/it]\u001b[A\n","Iteration:  19% 137/719 [29:31<2:05:52, 12.98s/it]\u001b[A\n","Iteration:  19% 138/719 [29:44<2:05:11, 12.93s/it]\u001b[A\n","Iteration:  19% 139/719 [29:57<2:05:09, 12.95s/it]\u001b[A\n","Iteration:  19% 140/719 [30:09<2:05:03, 12.96s/it]\u001b[A\n","Iteration:  20% 141/719 [30:22<2:04:49, 12.96s/it]\u001b[A\n","Iteration:  20% 142/719 [30:35<2:04:11, 12.91s/it]\u001b[A\n","Iteration:  20% 143/719 [30:48<2:04:11, 12.94s/it]\u001b[A\n","Iteration:  20% 144/719 [31:01<2:04:15, 12.97s/it]\u001b[A\n","Iteration:  20% 145/719 [31:14<2:04:10, 12.98s/it]\u001b[A\n","Iteration:  20% 146/719 [31:27<2:03:58, 12.98s/it]\u001b[A\n","Iteration:  20% 147/719 [31:40<2:03:54, 13.00s/it]\u001b[A\n","Iteration:  21% 148/719 [31:53<2:03:49, 13.01s/it]\u001b[A\n","Iteration:  21% 149/719 [32:06<2:03:43, 13.02s/it]\u001b[A09/26/2019 13:18:23 - INFO - transformers.configuration_utils -   Configuration saved in /tmp/STS/checkpoint-150/config.json\n","09/26/2019 13:18:25 - INFO - transformers.modeling_utils -   Model weights saved in /tmp/STS/checkpoint-150/pytorch_model.bin\n","09/26/2019 13:18:25 - INFO - __main__ -   Saving model checkpoint to /tmp/STS/checkpoint-150\n","\n","Iteration:  21% 150/719 [32:21<2:08:21, 13.54s/it]\u001b[A\n","Iteration:  21% 151/719 [32:34<2:06:48, 13.39s/it]\u001b[A\n","Iteration:  21% 152/719 [32:47<2:05:16, 13.26s/it]\u001b[A\n","Iteration:  21% 153/719 [33:00<2:04:21, 13.18s/it]\u001b[A\n","Iteration:  21% 154/719 [33:13<2:03:18, 13.09s/it]\u001b[A\n","Iteration:  22% 155/719 [33:26<2:02:45, 13.06s/it]\u001b[A\n","Iteration:  22% 156/719 [33:39<2:02:19, 13.04s/it]\u001b[A\n","Iteration:  22% 157/719 [33:52<2:01:58, 13.02s/it]\u001b[A\n","Iteration:  22% 158/719 [34:05<2:01:30, 13.00s/it]\u001b[A\n","Iteration:  22% 159/719 [34:18<2:01:07, 12.98s/it]\u001b[A\n","Iteration:  22% 160/719 [34:31<2:00:50, 12.97s/it]\u001b[A\n","Iteration:  22% 161/719 [34:44<2:00:08, 12.92s/it]\u001b[A\n","Iteration:  23% 162/719 [34:56<1:59:27, 12.87s/it]\u001b[A\n","Iteration:  23% 163/719 [35:09<1:59:00, 12.84s/it]\u001b[A\n","Iteration:  23% 164/719 [35:22<1:58:40, 12.83s/it]\u001b[A\n","Iteration:  23% 165/719 [35:35<1:58:25, 12.83s/it]\u001b[A\n","Iteration:  23% 166/719 [35:48<1:58:11, 12.82s/it]\u001b[A\n","Iteration:  23% 167/719 [36:00<1:58:02, 12.83s/it]\u001b[A\n","Iteration:  23% 168/719 [36:13<1:57:39, 12.81s/it]\u001b[A\n","Iteration:  24% 169/719 [36:26<1:57:27, 12.81s/it]\u001b[A\n","Iteration:  24% 170/719 [36:39<1:57:12, 12.81s/it]\u001b[A\n","Iteration:  24% 171/719 [36:52<1:57:24, 12.86s/it]\u001b[A\n","Iteration:  24% 172/719 [37:05<1:57:25, 12.88s/it]\u001b[A\n","Iteration:  24% 173/719 [37:18<1:57:26, 12.91s/it]\u001b[A\n","Iteration:  24% 174/719 [37:31<1:56:58, 12.88s/it]\u001b[A\n","Iteration:  24% 175/719 [37:43<1:56:42, 12.87s/it]\u001b[A\n","Iteration:  24% 176/719 [37:56<1:56:21, 12.86s/it]\u001b[A\n","Iteration:  25% 177/719 [38:09<1:56:18, 12.88s/it]\u001b[A\n","Iteration:  25% 178/719 [38:22<1:56:14, 12.89s/it]\u001b[A\n","Iteration:  25% 179/719 [38:35<1:56:10, 12.91s/it]\u001b[A\n","Iteration:  25% 180/719 [38:48<1:55:55, 12.90s/it]\u001b[A\n","Iteration:  25% 181/719 [39:01<1:55:50, 12.92s/it]\u001b[A\n","Iteration:  25% 182/719 [39:14<1:55:26, 12.90s/it]\u001b[A\n","Iteration:  25% 183/719 [39:27<1:55:08, 12.89s/it]\u001b[A\n","Iteration:  26% 184/719 [39:39<1:54:57, 12.89s/it]\u001b[A\n","Iteration:  26% 185/719 [39:52<1:54:40, 12.88s/it]\u001b[A\n","Iteration:  26% 186/719 [40:05<1:54:27, 12.88s/it]\u001b[A\n","Iteration:  26% 187/719 [40:18<1:54:20, 12.90s/it]\u001b[A\n","Iteration:  26% 188/719 [40:31<1:53:55, 12.87s/it]\u001b[A\n","Iteration:  26% 189/719 [40:44<1:53:42, 12.87s/it]\u001b[A\n","Iteration:  26% 190/719 [40:57<1:53:32, 12.88s/it]\u001b[A\n","Iteration:  27% 191/719 [41:10<1:53:19, 12.88s/it]\u001b[A\n","Iteration:  27% 192/719 [41:22<1:53:09, 12.88s/it]\u001b[A\n","Iteration:  27% 193/719 [41:35<1:52:59, 12.89s/it]\u001b[A\n","Iteration:  27% 194/719 [41:48<1:52:51, 12.90s/it]\u001b[A\n","Iteration:  27% 195/719 [42:01<1:52:42, 12.91s/it]\u001b[A\n","Iteration:  27% 196/719 [42:14<1:52:27, 12.90s/it]\u001b[A\n","Iteration:  27% 197/719 [42:27<1:52:22, 12.92s/it]\u001b[A\n","Iteration:  28% 198/719 [42:40<1:52:05, 12.91s/it]\u001b[A\n","Iteration:  28% 199/719 [42:53<1:51:50, 12.91s/it]\u001b[A09/26/2019 13:29:09 - INFO - transformers.configuration_utils -   Configuration saved in /tmp/STS/checkpoint-200/config.json\n","09/26/2019 13:29:12 - INFO - transformers.modeling_utils -   Model weights saved in /tmp/STS/checkpoint-200/pytorch_model.bin\n","09/26/2019 13:29:12 - INFO - __main__ -   Saving model checkpoint to /tmp/STS/checkpoint-200\n","\n","Iteration:  28% 200/719 [43:08<1:57:49, 13.62s/it]\u001b[A\n","Iteration:  28% 201/719 [43:21<1:55:47, 13.41s/it]\u001b[A\n","Iteration:  28% 202/719 [43:34<1:54:16, 13.26s/it]\u001b[A\n","Iteration:  28% 203/719 [43:47<1:53:13, 13.17s/it]\u001b[A\n","Iteration:  28% 204/719 [44:00<1:52:21, 13.09s/it]\u001b[A\n","Iteration:  29% 205/719 [44:13<1:51:39, 13.03s/it]\u001b[A\n","Iteration:  29% 206/719 [44:26<1:51:13, 13.01s/it]\u001b[A\n","Iteration:  29% 207/719 [44:39<1:50:47, 12.98s/it]\u001b[A\n","Iteration:  29% 208/719 [44:51<1:50:18, 12.95s/it]\u001b[A\n","Iteration:  29% 209/719 [45:04<1:50:02, 12.95s/it]\u001b[A\n","Iteration:  29% 210/719 [45:17<1:49:41, 12.93s/it]\u001b[A\n","Iteration:  29% 211/719 [45:30<1:49:24, 12.92s/it]\u001b[A\n","Iteration:  29% 212/719 [45:43<1:49:22, 12.94s/it]\u001b[A\n","Iteration:  30% 213/719 [45:56<1:49:20, 12.97s/it]\u001b[A\n","Iteration:  30% 214/719 [46:09<1:49:32, 13.02s/it]\u001b[A\n","Iteration:  30% 215/719 [46:22<1:49:27, 13.03s/it]\u001b[A\n","Iteration:  30% 216/719 [46:36<1:49:23, 13.05s/it]\u001b[A\n","Iteration:  30% 217/719 [46:49<1:49:08, 13.05s/it]\u001b[A\n","Iteration:  30% 218/719 [47:02<1:48:59, 13.05s/it]\u001b[A\n","Iteration:  30% 219/719 [47:15<1:48:33, 13.03s/it]\u001b[A\n","Iteration:  31% 220/719 [47:28<1:48:16, 13.02s/it]\u001b[A\n","Iteration:  31% 221/719 [47:41<1:48:02, 13.02s/it]\u001b[A\n","Iteration:  31% 222/719 [47:54<1:47:48, 13.01s/it]\u001b[A\n","Iteration:  31% 223/719 [48:07<1:47:38, 13.02s/it]\u001b[A\n","Iteration:  31% 224/719 [48:20<1:47:16, 13.00s/it]\u001b[A\n","Iteration:  31% 225/719 [48:33<1:47:32, 13.06s/it]\u001b[A\n","Iteration:  31% 226/719 [48:46<1:47:18, 13.06s/it]\u001b[A\n","Iteration:  32% 227/719 [48:59<1:47:07, 13.06s/it]\u001b[A\n","Iteration:  32% 228/719 [49:12<1:46:37, 13.03s/it]\u001b[A\n","Iteration:  32% 229/719 [49:25<1:46:04, 12.99s/it]\u001b[A\n","Iteration:  32% 230/719 [49:38<1:45:51, 12.99s/it]\u001b[A\n","Iteration:  32% 231/719 [49:51<1:45:30, 12.97s/it]\u001b[A\n","Iteration:  32% 232/719 [50:04<1:45:15, 12.97s/it]\u001b[A\n","Iteration:  32% 233/719 [50:17<1:44:59, 12.96s/it]\u001b[A\n","Iteration:  33% 234/719 [50:30<1:45:01, 12.99s/it]\u001b[A\n","Iteration:  33% 235/719 [50:43<1:44:46, 12.99s/it]\u001b[A\n","Iteration:  33% 236/719 [50:56<1:44:28, 12.98s/it]\u001b[A\n","Iteration:  33% 237/719 [51:09<1:44:19, 12.99s/it]\u001b[A\n","Iteration:  33% 238/719 [51:22<1:44:04, 12.98s/it]\u001b[A\n","Iteration:  33% 239/719 [51:34<1:43:38, 12.95s/it]\u001b[A\n","Iteration:  33% 240/719 [51:47<1:43:10, 12.92s/it]\u001b[A\n","Iteration:  34% 241/719 [52:00<1:42:56, 12.92s/it]\u001b[A\n","Iteration:  34% 242/719 [52:13<1:42:37, 12.91s/it]\u001b[A\n","Iteration:  34% 243/719 [52:26<1:42:29, 12.92s/it]\u001b[A\n","Iteration:  34% 244/719 [52:39<1:42:02, 12.89s/it]\u001b[A\n","Iteration:  34% 245/719 [52:52<1:42:01, 12.91s/it]\u001b[A\n","Iteration:  34% 246/719 [53:05<1:41:42, 12.90s/it]\u001b[A\n","Iteration:  34% 247/719 [53:18<1:41:17, 12.88s/it]\u001b[A\n","Iteration:  34% 248/719 [53:30<1:41:07, 12.88s/it]\u001b[A\n","Iteration:  35% 249/719 [53:43<1:40:55, 12.88s/it]\u001b[A09/26/2019 13:40:00 - INFO - transformers.configuration_utils -   Configuration saved in /tmp/STS/checkpoint-250/config.json\n","09/26/2019 13:40:02 - INFO - transformers.modeling_utils -   Model weights saved in /tmp/STS/checkpoint-250/pytorch_model.bin\n","09/26/2019 13:40:02 - INFO - __main__ -   Saving model checkpoint to /tmp/STS/checkpoint-250\n","\n","Iteration:  35% 250/719 [53:58<1:45:12, 13.46s/it]\u001b[A\n","Iteration:  35% 251/719 [54:11<1:44:02, 13.34s/it]\u001b[A\n","Iteration:  35% 252/719 [54:24<1:42:53, 13.22s/it]\u001b[A\n","Iteration:  35% 253/719 [54:37<1:42:09, 13.15s/it]\u001b[A\n","Iteration:  35% 254/719 [54:50<1:41:22, 13.08s/it]\u001b[A\n","Iteration:  35% 255/719 [55:03<1:40:38, 13.01s/it]\u001b[A\n","Iteration:  36% 256/719 [55:16<1:40:05, 12.97s/it]\u001b[A\n","Iteration:  36% 257/719 [55:29<1:39:52, 12.97s/it]\u001b[A\n","Iteration:  36% 258/719 [55:42<1:39:52, 13.00s/it]\u001b[A\n","Iteration:  36% 259/719 [55:55<1:39:24, 12.97s/it]\u001b[A\n","Iteration:  36% 260/719 [56:08<1:38:57, 12.93s/it]\u001b[A\n","Iteration:  36% 261/719 [56:21<1:38:47, 12.94s/it]\u001b[A\n","Iteration:  36% 262/719 [56:33<1:38:28, 12.93s/it]\u001b[A\n","Iteration:  37% 263/719 [56:46<1:38:23, 12.95s/it]\u001b[A\n","Iteration:  37% 264/719 [56:59<1:38:14, 12.96s/it]\u001b[A\n","Iteration:  37% 265/719 [57:12<1:37:34, 12.90s/it]\u001b[A\n","Iteration:  37% 266/719 [57:25<1:37:03, 12.86s/it]\u001b[A\n","Iteration:  37% 267/719 [57:38<1:36:19, 12.79s/it]\u001b[A\n","Iteration:  37% 268/719 [57:50<1:36:14, 12.80s/it]\u001b[A\n","Iteration:  37% 269/719 [58:03<1:36:08, 12.82s/it]\u001b[A\n","Iteration:  38% 270/719 [58:16<1:35:30, 12.76s/it]\u001b[A\n","Iteration:  38% 271/719 [58:29<1:35:18, 12.76s/it]\u001b[A\n","Iteration:  38% 272/719 [58:41<1:34:45, 12.72s/it]\u001b[A\n","Iteration:  38% 273/719 [58:54<1:34:21, 12.69s/it]\u001b[A\n","Iteration:  38% 274/719 [59:07<1:34:44, 12.77s/it]\u001b[A\n","Iteration:  38% 275/719 [59:20<1:34:52, 12.82s/it]\u001b[A\n","Iteration:  38% 276/719 [59:33<1:35:03, 12.87s/it]\u001b[A\n","Iteration:  39% 277/719 [59:46<1:35:02, 12.90s/it]\u001b[A\n","Iteration:  39% 278/719 [59:59<1:34:59, 12.92s/it]\u001b[A\n","Iteration:  39% 279/719 [1:00:12<1:34:54, 12.94s/it]\u001b[A\n","Iteration:  39% 280/719 [1:00:25<1:34:45, 12.95s/it]\u001b[A\n","Iteration:  39% 281/719 [1:00:38<1:34:48, 12.99s/it]\u001b[A\n","Iteration:  39% 282/719 [1:00:51<1:34:36, 12.99s/it]\u001b[A\n","Iteration:  39% 283/719 [1:01:04<1:34:17, 12.98s/it]\u001b[A\n","Iteration:  39% 284/719 [1:01:17<1:34:02, 12.97s/it]\u001b[A\n","Iteration:  40% 285/719 [1:01:30<1:34:10, 13.02s/it]\u001b[A\n","Iteration:  40% 286/719 [1:01:43<1:33:28, 12.95s/it]\u001b[A\n","Iteration:  40% 287/719 [1:01:55<1:33:06, 12.93s/it]\u001b[A\n","Iteration:  40% 288/719 [1:02:08<1:32:49, 12.92s/it]\u001b[A\n","Iteration:  40% 289/719 [1:02:21<1:32:24, 12.89s/it]\u001b[A\n","Iteration:  40% 290/719 [1:02:34<1:32:00, 12.87s/it]\u001b[A\n","Iteration:  40% 291/719 [1:02:47<1:31:24, 12.81s/it]\u001b[A\n","Iteration:  41% 292/719 [1:03:00<1:31:39, 12.88s/it]\u001b[A\n","Iteration:  41% 293/719 [1:03:13<1:31:45, 12.92s/it]\u001b[A\n","Iteration:  41% 294/719 [1:03:26<1:31:35, 12.93s/it]\u001b[A\n","Iteration:  41% 295/719 [1:03:39<1:31:18, 12.92s/it]\u001b[A\n","Iteration:  41% 296/719 [1:03:51<1:31:05, 12.92s/it]\u001b[A\n","Iteration:  41% 297/719 [1:04:04<1:30:58, 12.93s/it]\u001b[A\n","Iteration:  41% 298/719 [1:04:17<1:30:40, 12.92s/it]\u001b[A\n","Iteration:  42% 299/719 [1:04:30<1:30:28, 12.92s/it]\u001b[A09/26/2019 13:50:47 - INFO - transformers.configuration_utils -   Configuration saved in /tmp/STS/checkpoint-300/config.json\n","09/26/2019 13:50:48 - INFO - transformers.modeling_utils -   Model weights saved in /tmp/STS/checkpoint-300/pytorch_model.bin\n","09/26/2019 13:50:48 - INFO - __main__ -   Saving model checkpoint to /tmp/STS/checkpoint-300\n","\n","Iteration:  42% 300/719 [1:04:45<1:33:33, 13.40s/it]\u001b[A\n","Iteration:  42% 301/719 [1:04:58<1:32:07, 13.22s/it]\u001b[A\n","Iteration:  42% 302/719 [1:05:10<1:31:12, 13.12s/it]\u001b[A\n","Iteration:  42% 303/719 [1:05:24<1:30:52, 13.11s/it]\u001b[A\n","Iteration:  42% 304/719 [1:05:36<1:30:12, 13.04s/it]\u001b[A\n","Iteration:  42% 305/719 [1:05:49<1:29:45, 13.01s/it]\u001b[A\n","Iteration:  43% 306/719 [1:06:02<1:29:37, 13.02s/it]\u001b[A\n","Iteration:  43% 307/719 [1:06:15<1:29:17, 13.00s/it]\u001b[A\n","Iteration:  43% 308/719 [1:06:28<1:29:08, 13.01s/it]\u001b[A\n","Iteration:  43% 309/719 [1:06:42<1:29:11, 13.05s/it]\u001b[A\n","Iteration:  43% 310/719 [1:06:55<1:29:10, 13.08s/it]\u001b[A\n","Iteration:  43% 311/719 [1:07:08<1:28:59, 13.09s/it]\u001b[A\n","Iteration:  43% 312/719 [1:07:21<1:28:48, 13.09s/it]\u001b[A\n","Iteration:  44% 313/719 [1:07:34<1:28:14, 13.04s/it]\u001b[A\n","Iteration:  44% 314/719 [1:07:47<1:27:41, 12.99s/it]\u001b[A\n","Iteration:  44% 315/719 [1:08:00<1:27:16, 12.96s/it]\u001b[A\n","Iteration:  44% 316/719 [1:08:13<1:26:59, 12.95s/it]\u001b[A\n","Iteration:  44% 317/719 [1:08:25<1:26:39, 12.94s/it]\u001b[A\n","Iteration:  44% 318/719 [1:08:38<1:26:22, 12.92s/it]\u001b[A\n","Iteration:  44% 319/719 [1:08:51<1:25:56, 12.89s/it]\u001b[A\n","Iteration:  45% 320/719 [1:09:04<1:25:55, 12.92s/it]\u001b[A\n","Iteration:  45% 321/719 [1:09:17<1:25:50, 12.94s/it]\u001b[A\n","Iteration:  45% 322/719 [1:09:30<1:25:48, 12.97s/it]\u001b[A\n","Iteration:  45% 323/719 [1:09:43<1:25:28, 12.95s/it]\u001b[A\n","Iteration:  45% 324/719 [1:09:56<1:24:47, 12.88s/it]\u001b[A\n","Iteration:  45% 325/719 [1:10:09<1:24:19, 12.84s/it]\u001b[A\n","Iteration:  45% 326/719 [1:10:21<1:23:45, 12.79s/it]\u001b[A\n","Iteration:  45% 327/719 [1:10:34<1:23:33, 12.79s/it]\u001b[A\n","Iteration:  46% 328/719 [1:10:47<1:23:15, 12.78s/it]\u001b[A\n","Iteration:  46% 329/719 [1:11:00<1:23:03, 12.78s/it]\u001b[A\n","Iteration:  46% 330/719 [1:11:12<1:22:48, 12.77s/it]\u001b[A\n","Iteration:  46% 331/719 [1:11:25<1:22:38, 12.78s/it]\u001b[A\n","Iteration:  46% 332/719 [1:11:38<1:22:34, 12.80s/it]\u001b[A\n","Iteration:  46% 333/719 [1:11:51<1:22:41, 12.85s/it]\u001b[A\n","Iteration:  46% 334/719 [1:12:04<1:22:44, 12.90s/it]\u001b[A\n","Iteration:  47% 335/719 [1:12:17<1:22:26, 12.88s/it]\u001b[A\n","Iteration:  47% 336/719 [1:12:30<1:22:16, 12.89s/it]\u001b[A\n","Iteration:  47% 337/719 [1:12:42<1:21:59, 12.88s/it]\u001b[A\n","Iteration:  47% 338/719 [1:12:55<1:21:46, 12.88s/it]\u001b[A\n","Iteration:  47% 339/719 [1:13:08<1:21:25, 12.86s/it]\u001b[A\n","Iteration:  47% 340/719 [1:13:21<1:21:16, 12.87s/it]\u001b[A\n","Iteration:  47% 341/719 [1:13:34<1:21:17, 12.90s/it]\u001b[A\n","Iteration:  48% 342/719 [1:13:47<1:21:13, 12.93s/it]\u001b[A\n","Iteration:  48% 343/719 [1:14:00<1:20:55, 12.91s/it]\u001b[A\n","Iteration:  48% 344/719 [1:14:13<1:20:52, 12.94s/it]\u001b[A\n","Iteration:  48% 345/719 [1:14:26<1:20:41, 12.95s/it]\u001b[A"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4gsEbnUAi4qr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}